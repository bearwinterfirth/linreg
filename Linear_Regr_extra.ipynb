{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linjär regression på en variabel\n",
    "\n",
    "Vi kommer här att titta på endast en av x-variablerna (_Geometric_), då vi tidigare konstaterat att det finns hög grad av beroende mellan de olika x-variablerna, och därför blir den förra modellen otillförlitlig.\n",
    "\n",
    "Många av beräkningarna blir likadana som i första exemplet, och vi utför dem därför lite \"fler åt gången\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import LR\n",
    "\n",
    "data_path = \"Small-diameter-flow.csv\"\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "\n",
    "y = df[\"Flow\"]\n",
    "X = np.column_stack([np.ones(y.shape[0]), df['Geometric']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu söker vi alltså ett linjärt samband på formen\n",
    "$$\n",
    "y=\\beta_0 + \\beta_1 [Geometric]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vi får β0 = 5.3323804, β1 = 3.2400047\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = LR.LinearRegression()\n",
    "b = m.fit(X, y)\n",
    "print(f\"Vi får β0 = {b[0]:.7f}, β1 = {b[1]:.7f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi noterar speciellt att $\\beta_1$, alltså lutningsparameterna för _Geometric_, blir 3.24, att jämföra med 3.61 från första försöket. (Det går förstås inte att jämföra rakt av, många andra faktorer spelar in, men kan ändå ge en hint om hur lika eller olika modellerna blir.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = 1, n = 198\n",
      "Variansen är 0.0182068\n",
      "S = 0.1349327, Syy = 425.1441930, SSR = 421.5756511\n"
     ]
    }
   ],
   "source": [
    "d = m.dimension(b)\n",
    "n = m.sample_size(y)\n",
    "print(f\"d = {d}, n = {n}\")\n",
    "\n",
    "SSE = m.SSE(y, X, b)\n",
    "var = m.variance(SSE, n, d)\n",
    "print(f\"Variansen är {var:.7f}\")\n",
    "\n",
    "S = m.deviation(var)\n",
    "Syy = m.Syy(n, y)\n",
    "SSR = m.SSR(Syy, SSE)\n",
    "print(f\"S = {S:.7f}, Syy = {Syy:.7f}, SSR = {SSR:.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Värdet på standardavvikelsen har samma dimension som x-variablerna, men eftersom dessa var logaritmerade, så blir även S dimensionslös. Det är dock ett slags mått på hur stora avvikelserna är från medlet, i medeltal.\n",
    "\n",
    "SSR och Syy säger oss inte heller så mycket i nuläget, utan behövs mest för att räkna fram de viktiga statistikor vi behöver för att avgöra modellens relevans.\n",
    "\n",
    "Nu ska vi beräkna F-värdet (\"_F-statistic_\"). Ett högt F-värde (långt från 1) innebär att det finns ett relevant samband mellan vårt X och y, alltså att vår modell i någon mening \"makes sense\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = 22398.7658956827\n"
     ]
    }
   ],
   "source": [
    "F = m.Fstatistic(SSR, d, var)\n",
    "print(f\"F = {F}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ett högt värde, så det är ingen tvekan om att det finns ett tydligt samband. Fortfarande finns dock en risk att sambandet är \"skevt\", då det kan påverkas av att X-variablerna inte är oberoende, vilket vi återkommer till.\n",
    "\n",
    "Vi kan även beräkna $R^2$ (ibland kallad _Rsq_), som ger ett mått på hur stor andel av variansen i materialet som kan förklaras av vår modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq = 0.9971212473210772\n"
     ]
    }
   ],
   "source": [
    "Rsq = m.Rsq(SSR, Syy)\n",
    "print(f\"Rsq = {Rsq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi fick alltså ett mycket högt värde på $R^2$, 0,997 motsvarar inte mindre än 3 standardavvikelser (3 $\\sigma$) ! En mycket stor del av variansen kan alltså förklaras av vår modell.\n",
    "\n",
    "Men - kanske är det så att vår modell är \"för bra för att vara sann\"? Om våra x-variabler inte är oberoende, kan det påverka modellen i stor utsträckning. Det kan både vara så att de \"ger varandra draghjälp\", eller motverkar varandra. Det kan också vara så att någon variabel är mer eller mindre betydelselös.\n",
    "\n",
    "För att testa detta, gör vi ett s.k. _dependency check_, \"beroende-test\". Vi beräknar Pearson-r för varje kombination av två x-variabler, i vårt fall blir det alltså sammanlagt tre tester. Om vi får r-värden nära 1 eller -1, innebär det att det är ett tydligt samband. I samband med detta får vi även fram _p-värdet_, som är ett mått på sannolikheten att det inte skulle finnas något samband. Ett p-värde nära 0 gör att vi kan vara mycket säkra på att det _finns_ ett samband."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinematic / geometric: r = 0.8631351, p = 4.5604633624399433e-60\n",
      "kinematic / inertial: r = 0.9686708, p = 1.588545639896567e-120\n",
      "geometric / inertial: r = 0.9183300, p = 7.951572627158216e-81\n"
     ]
    }
   ],
   "source": [
    "# Dependency check\n",
    "\n",
    "print(f\"kinematic / geometric: r = {m.Pearsonr(X, 1, 2)[0]:.7f}, p = {m.Pearsonr(X, 1, 2)[1]}\")\n",
    "print(f\"kinematic / inertial: r = {m.Pearsonr(X, 1, 3)[0]:.7f}, p = {m.Pearsonr(X, 1, 3)[1]}\")\n",
    "print(f\"geometric / inertial: r = {m.Pearsonr(X, 2, 3)[0]:.7f}, p = {m.Pearsonr(X, 2, 3)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi har alltså \"tyvärr\" tydliga beroenden mellan alla tre x-variablerna, vilket gör att den modell vi räknat ut är näst intill värdelös! Det kan vara så att de olika variablerna påverkar varandra, eller så kan en av variablerna \"följa med på köpet\" när en annan ökar, och därmed vara ganska irrelevant på egen hand!\n",
    "\n",
    "Vi ska titta lite på signifikansen hos de olika β-parametrarna, för att se om vi kan få någon ledtråd. Vi börjar med att beräkna varians/kovarians-matrisen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1786122  -0.01993074 -0.00513088  0.01567684]\n",
      " [-0.01993074  0.00237237  0.00043044 -0.00168614]\n",
      " [-0.00513088  0.00043044  0.00108079 -0.0008474 ]\n",
      " [ 0.01567684 -0.00168614 -0.0008474   0.00154512]]\n"
     ]
    }
   ],
   "source": [
    "# Beräkna varians/kovarians-matris\n",
    "c = m.var_covar(X, var)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kommer att göra ett tvåsidigt relevanstest, där vi kommer att välja den minsta av de två \"svansarna\" som vi får genom att titta på den kumulativa distributionsfunktionen, respektive \"survival-funktionen\". För att göra detta test vehövs värdena längs diagonalen i varians/kovariansmatrisen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevansen för β0 är 1.369442865878956e-146\n",
      "Relevansen för β1 är 2.279977868333894e-236\n",
      "Relevansen för β2 är 0.0\n",
      "Relevansen för β3 är 1.9192830886558436e-242\n"
     ]
    }
   ],
   "source": [
    "# beräkna signifikans för de enskilda β-parametrarna\n",
    "sig=[]\n",
    "for a in range(d+1):\n",
    "    sig.append(m.significance(a,b,c,S))\n",
    "for a in range(d+1):\n",
    "    print(f\"Relevansen för β{a} är {m.relevance(sig, a, n, d)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser att vi har värden extremt nära 0 i samtliga fall, det är alltså i princip omöjligt att de inte är signifikanta. Men återigen, detta kan påverkas av deras inbördes beroende.\n",
    "\n",
    "Vi vill även presentera ett konfidensintervall för de olika β-parametrarna, och vi vill välja en konfidensnivå på 95%. Därmed behöver vi börja med att beräkna lämpligt $t_{\\alpha/2}$ på T-kurvan, alltså hur många standardavvikelser vi avviker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-värdet är 1.972267532579456\n",
      "Konfidensintervallet för β0 på 95%-nivån är mellan -2.554534655293283 och -2.5650516160478123\n",
      "Konfidensintervallet för β1 på 95%-nivån är mellan 0.8693212249244441 och 0.8681091588053166\n",
      "Konfidensintervallet för β2 på 95%-nivån är mellan 3.610827229208975 och 3.610009129744773\n",
      "Konfidensintervallet för β3 på 95%-nivån är mellan -0.7531986370351633 och -0.754176809399355\n"
     ]
    }
   ],
   "source": [
    "print(f\"t-värdet är {stats.t.ppf(1-0.05/2,n-d-1)}\")\n",
    "for a in range(d+1):\n",
    "    ci=m.confidence_interval(n,d,var,c,a)\n",
    "    print(f\"Konfidensintervallet för β{a} på 95%-nivån är mellan {b[a]+ci} och {b[a]-ci}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t_{\\alpha/2}$-värdet på ca 1,97 motsvarar alltså ungefär 2 standardavvikelser, så vi kan ge ovanstående mått på β-parametrarna med 95% säkerhet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Men, som vi tidigare konstaterat så är alla dessa siffror egentligen ganska ointressanta, då vi konstaterat att vår modell har en stor svaghet; de olika x-variablerna är i olika grad beroende av varandra. Vi bör därför testa andra modeller, vi skulle exempelvis kunna testa att låta en variabel vara $x_2\\cdot x_3$, ellar att göra en regression på bara två av x-variablerna, eller någon annan kombination. Det blir dock litte tids- och utrymmeskrävande, så vi nöjer oss med att helt enkelt göra en regression y som funktion av en enda av x-variablerna. Vi väljer _Geometric_ eftersom vi har tjuvtittat på en _scatter matrix_, och sambandet mellan _Geometric_ och _Flow_ ser ut att vara det allra tydligaste.\n",
    "\n",
    "Vi kommer alltså att göra de flesta av ovanstående beräkningar igen, men nu bara i _en_ x-variabel. Detta görs i filen _Linear_Regr_extra.ipynb_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
