{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboration Statistiska Metoder\n",
    "_Björn Winterfjord_\n",
    "\n",
    "Vi börjar med att importera nödvändiga bibliotek, inklusive filen <span style = \"color:green\">LR.py</span>, där våra funktioner för linjär regression finns. Därefter läser vi in datafilen <span style = \"color:green\">Small-diameter-flow.csv</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import LR\n",
    "\n",
    "data_path = \"Small-diameter-flow.csv\"\n",
    "df = pd.read_csv(data_path, index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi låter responsvektorn y vara kolumnen <span style = \"color:green\">Flow</span>, och vi ska undersöka om det finns något samband mellan denna och de tre variablerna <span style = \"color:green\">Kinematic</span>, <span style = \"color:green\">Geometric</span> och <span style = \"color:green\">Inertial</span>. Vi sparar dessa tre kolumner i vår designmatris <span style = \"color:green\">X</span>, tillsammans med en kolumn med 1:or.\n",
    "\n",
    "Vi tar alltså inte med kolumnen <span style = \"color:green\">Observer</span> i nuläget, men kommer senare att underöka om det finns något observatörsbias i experimentet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Flow\"]\n",
    "X = np.column_stack([np.ones(y.shape[0]), df['Kinematic'], df['Geometric'], df['Inertial']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu utför vi (med hjälp av linjär algebra) vår linjära regression genom att anropa funktionen <span style = \"color:green\">fit</span> från <span style = \"color:green\">LR.py</span>. Vi söker ett linjärt samband på formen\n",
    "$$\n",
    "y=\\beta_0 + \\beta_1 [Kinematic] + \\beta_2 [Geometric] + \\beta_3[Inertial]\n",
    "$$\n",
    "där $\\beta_0$ är interceptet och $\\beta_1$, $\\beta_2$ och $\\beta_3$ är parametrar för de olika x-variablerna. Vi kommer senare att utvärdera rimligheten i denna modell.\n",
    "\n",
    "De olika $\\beta$-värdena lagras i listan _b_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vi får β0 = -2.5597931, β1 = 0.8687152, β2 = 3.6104182, β3 = -0.7536877\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = LR.LinearRegression()\n",
    "b = m.fit(X, y)\n",
    "print(f\"Vi får β0 = {b[0]:.7f}, β1 = {b[1]:.7f}, β2 = {b[2]:.7f}, β3 = {b[3]:.7f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det finns en risk att de olika x-variablerna inte är oberoende av varandra, och vi kommer därför senare att göra en _dependency check_ för att utröna om så är fallet. Men vi ska börja med att utvärdera ovanstående modell. Det första vi gör är att ta fram dimensionstalet _d_ (vi vet redan att det kommer att bli 3), samt storleken på stickprovet, _n_. Dessa värden kommer vi att behöve vid flera tillfällen i vår kommande analys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = 3, n = 198\n"
     ]
    }
   ],
   "source": [
    "d = m.dimension(b)\n",
    "n = m.sample_size(y)\n",
    "print(f\"d = {d}, n = {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu ska vi beräkna _variansen_ i vårt material, och för att kunna göra det behöver vi först beräkna SSE, _sum of square errors_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variansen är 0.0063087\n"
     ]
    }
   ],
   "source": [
    "# X = designmatrisen, y = responsvektorn, b = listan över β-värden\n",
    "# n = sample size, d = dimensionen, var = variansen\n",
    "SSE = m.SSE(y, X, b)\n",
    "var = m.variance(SSE, n, d)\n",
    "print(f\"Variansen är {var:.7f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Värdet på variansen säger oss inte så mycket, dels eftersom den är dimensionslös, och dels eftersom vi inte har något liknande experiment att jämföra med. Dessutom är både våra x- och y-värden logaritmerade.\n",
    "\n",
    "Nu ska vi beräkna standardavvikelsen $S$ (som ju är roten ur variansen) och variansen bland y-värdena, $S_{yy}$. Därefter kan vi beräkna $SSR$, _sum of square residuals_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S = 0.0794272, Syy = 425.1441930, SSR = 423.9203080\n"
     ]
    }
   ],
   "source": [
    "S = m.deviation(var)\n",
    "Syy = m.Syy(n, y)\n",
    "SSR = m.SSR(Syy, SSE)\n",
    "\n",
    "print(f\"S = {S:.7f}, Syy = {Syy:.7f}, SSR = {SSR:.7f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Värdet på standardavvikelsen har samma dimension som x-variablerna, men eftersom dessa var logaritmerade, så blir även S dimensionslös. Det är dock ett slags mått på hur stora avvikelserna är från medlet, i medeltal.\n",
    "\n",
    "SSR och Syy säger oss inte heller så mycket i nuläget, utan behövs mest för att räkna fram de viktiga statistikor vi behöver för att avgöra modellens relevans.\n",
    "\n",
    "Nu ska vi beräkna F-värdet (\"_F-statistic_\"). Ett högt F-värde (långt från 1) innebär att det finns ett relevant samband mellan vårt X och y, alltså att vår modell i någon mening \"makes sense\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = 22398.7658956827\n"
     ]
    }
   ],
   "source": [
    "F = m.Fstatistic(SSR, d, var)\n",
    "print(f\"F = {F}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ett högt värde, så det är ingen tvekan om att det finns ett tydligt samband. Fortfarande finns dock en risk att sambandet är \"skevt\", då det kan påverkas av att X-variablerna inte är oberoende, vilket vi återkommer till.\n",
    "\n",
    "Vi kan även beräkna $R^2$ (ibland kallad _Rsq_), som ger ett mått på hur stor andel av variansen i materialet som kan förklaras av vår modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq = 0.9971212473210772\n"
     ]
    }
   ],
   "source": [
    "Rsq = m.Rsq(SSR, Syy)\n",
    "print(f\"Rsq = {Rsq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi fick alltså ett mycket högt värde på $R^2$, 0,997 motsvarar inte mindre än 3 standardavvikelser (3 $\\sigma$) ! En mycket stor del av variansen kan alltså förklaras av vår modell.\n",
    "\n",
    "Men - kanske är det så att vår modell är \"för bra för att vara sann\"? Om våra x-variabler inte är oberoende, kan det påverka modellen i stor utsträckning. Det kan både vara så att de \"ger varandra draghjälp\", eller motverkar varandra. Det kan också vara så att någon variabel är mer eller mindre betydelselös.\n",
    "\n",
    "För att testa detta, gör vi ett s.k. _dependency check_, \"beroende-test\". Vi beräknar Pearson-r för varje kombination av två x-variabler, i vårt fall blir det alltså sammanlagt tre tester. Om vi får r-värden nära 1 eller -1, innebär det att det är ett tydligt samband. I samband med detta får vi även fram _p-värdet_, som är ett mått på sannolikheten att det inte skulle finnas något samband. Ett p-värde nära 0 gör att vi kan vara mycket säkra på att det _finns_ ett samband."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinematic / geometric: r = 0.8631351, p = 4.5604633624399433e-60\n",
      "kinematic / inertial: r = 0.9686708, p = 1.588545639896567e-120\n",
      "geometric / inertial: r = 0.9183300, p = 7.951572627158216e-81\n"
     ]
    }
   ],
   "source": [
    "# Dependency check\n",
    "\n",
    "print(f\"kinematic / geometric: r = {m.Pearsonr(X, 1, 2)[0]:.7f}, p = {m.Pearsonr(X, 1, 2)[1]}\")\n",
    "print(f\"kinematic / inertial: r = {m.Pearsonr(X, 1, 3)[0]:.7f}, p = {m.Pearsonr(X, 1, 3)[1]}\")\n",
    "print(f\"geometric / inertial: r = {m.Pearsonr(X, 2, 3)[0]:.7f}, p = {m.Pearsonr(X, 2, 3)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi har alltså \"tyvärr\" tydliga beroenden mellan alla tre x-variablerna, vilket gör att den modell vi räknat ut är näst intill värdelös! Det kan vara så att de olika variablerna påverkar varandra, eller så kan en av variablerna \"följa med på köpet\" när en annan ökar, och därmed vara ganska irrelevant på egen hand!\n",
    "\n",
    "Vi ska titta lite på signifikansen hos de olika β-parametrarna, för att se om vi kan få någon ledtråd. Vi börjar med att beräkna varians/kovarians-matrisen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1786122  -0.01993074 -0.00513088  0.01567684]\n",
      " [-0.01993074  0.00237237  0.00043044 -0.00168614]\n",
      " [-0.00513088  0.00043044  0.00108079 -0.0008474 ]\n",
      " [ 0.01567684 -0.00168614 -0.0008474   0.00154512]]\n"
     ]
    }
   ],
   "source": [
    "# Beräkna varians/kovarians-matris\n",
    "c = m.var_covar(X, var)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kommer att göra ett tvåsidigt relevanstest, där vi kommer att välja den minsta av de två \"svansarna\" som vi får genom att titta på den kumulativa distributionsfunktionen, respektive \"survival-funktionen\". För att göra detta test vehövs värdena längs diagonalen i varians/kovariansmatrisen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevansen för β0 är 1.369442865878956e-146\n",
      "Relevansen för β1 är 2.279977868333894e-236\n",
      "Relevansen för β2 är 0.0\n",
      "Relevansen för β3 är 1.9192830886558436e-242\n"
     ]
    }
   ],
   "source": [
    "# beräkna signifikans för de enskilda β-parametrarna\n",
    "sig=[]\n",
    "for a in range(d+1):\n",
    "    sig.append(m.significance(a,b,c,S))\n",
    "for a in range(d+1):\n",
    "    print(f\"Relevansen för β{a} är {m.relevance(sig, a, n, d)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser att vi har värden extremt nära 0 i samtliga fall, det är alltså i princip omöjligt att de inte är signifikanta. Men återigen, detta kan påverkas av deras inbördes beroende.\n",
    "\n",
    "Vi vill även presentera ett konfidensintervall för de olika β-parametrarna, och vi vill välja en konfidensnivå på 95%. Därmed behöver vi börja med att beräkna lämpligt $t_{\\alpha/2}$ på T-kurvan, alltså hur många standardavvikelser vi avviker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-värdet är 1.972267532579456\n",
      "Konfidensintervallet för β0 på 95%-nivån är mellan -2.554534655293283 och -2.5650516160478123\n",
      "Konfidensintervallet för β1 på 95%-nivån är mellan 0.8693212249244441 och 0.8681091588053166\n",
      "Konfidensintervallet för β2 på 95%-nivån är mellan 3.610827229208975 och 3.610009129744773\n",
      "Konfidensintervallet för β3 på 95%-nivån är mellan -0.7531986370351633 och -0.754176809399355\n"
     ]
    }
   ],
   "source": [
    "print(f\"t-värdet är {stats.t.ppf(1-0.05/2,n-d-1)}\")\n",
    "for a in range(d+1):\n",
    "    ci=m.confidence_interval(n,d,var,c,a)\n",
    "    print(f\"Konfidensintervallet för β{a} på 95%-nivån är mellan {b[a]+ci} och {b[a]-ci}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t_{\\alpha/2}$-värdet på ca 1,97 motsvarar alltså ungefär 2 standardavvikelser, så vi kan ge ovanstående mått på β-parametrarna med 95% säkerhet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Men, som vi tidigare konstaterat så är alla dessa siffror egentligen ganska ointressanta, då vi konstaterat att vår modell har en stor svaghet; de olika x-variablerna är i olika grad beroende av varandra. Vi bör därför testa andra modeller, vi skulle exempelvis kunna testa att låta en variabel vara $x_2 * x_3$, ellar att göra en regression på bara två av x-variablerna, eller någon annan kombination. Det blir dock litte tids- och utrymmeskrävande, så vi nöjer oss med att helt enkelt "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
